{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26989d69-0e01-405d-87a2-d21c928ea9a0",
   "metadata": {},
   "source": [
    "1. Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c91e607-f380-40a7-8a35-3969a55ffd59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.10.1+cu102\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a601943-3525-4a57-8011-3c737bf1b30b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)\n",
      "Python 3.8.10\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd522641-20fb-4ee4-8312-15e49803fb3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)\n",
      "Requirement already satisfied: gluonnlp==0.8.0 in /usr/local/lib/python3.8/dist-packages (0.8.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (1.4.1)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (4.63.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from gluonnlp==0.8.0) (1.21.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.8/dist-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: You are using pip version 22.0.4; however, version 23.1.2 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gluonnlp==0.8.0 pandas tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8a9aeff-e0da-4179-a81c-8902fad6c364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)\n",
      "Requirement already satisfied: mxnet in /usr/local/lib/python3.8/dist-packages (1.7.0.post2)\n",
      "Requirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.8/dist-packages (from mxnet) (1.21.0)\n",
      "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.8/dist-packages (from mxnet) (2.27.1)\n",
      "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.8/dist-packages (from mxnet) (0.8.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.20.0->mxnet) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.20.0->mxnet) (2.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.20.0->mxnet) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.20.0->mxnet) (1.25.11)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: You are using pip version 22.0.4; however, version 23.1.2 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install mxnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "141bd365-5bb2-4aff-aa86-87703e9292f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.8/dist-packages (0.1.96)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: You are using pip version 22.0.4; however, version 23.1.2 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fcb91ae6-a452-480c-a9b1-8d36dca30c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)\n",
      "Requirement already satisfied: openpyxl in /usr/local/lib/python3.8/dist-packages (3.1.2)\n",
      "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.8/dist-packages (from openpyxl) (1.1.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: You are using pip version 22.0.4; however, version 23.1.2 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13798552-3b8b-421f-a7b7-83b557012dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)\n",
      "Requirement already satisfied: numpy==1.21.0 in /usr/local/lib/python3.8/dist-packages (1.21.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: You are using pip version 22.0.4; however, version 23.1.2 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy==1.21.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b24fee39-3428-4d72-9351-e7cae465fdb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)\n",
      "Collecting git+https://****@github.com/SKTBrain/KoBERT.git@master\n",
      "  Cloning https://****@github.com/SKTBrain/KoBERT.git (to revision master) to /tmp/pip-req-build-uedp8uf2\n",
      "  Running command git clone --filter=blob:none --quiet 'https://****@github.com/SKTBrain/KoBERT.git' /tmp/pip-req-build-uedp8uf2\n",
      "  Resolved https://****@github.com/SKTBrain/KoBERT.git to commit 47a69af87928fc24e20f571fe10c3cc9dd9af9a3\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: boto3<=1.15.18 in /usr/local/lib/python3.8/dist-packages (from kobert==0.2.3) (1.15.18)\n",
      "Requirement already satisfied: gluonnlp<=0.10.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from kobert==0.2.3) (0.8.0)\n",
      "Requirement already satisfied: mxnet<=1.7.0.post2,>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from kobert==0.2.3) (1.7.0.post2)\n",
      "Requirement already satisfied: onnxruntime<=1.8.0,==1.8.0 in /usr/local/lib/python3.8/dist-packages (from kobert==0.2.3) (1.8.0)\n",
      "Requirement already satisfied: sentencepiece<=0.1.96,>=0.1.6 in /usr/local/lib/python3.8/dist-packages (from kobert==0.2.3) (0.1.96)\n",
      "Requirement already satisfied: torch<=1.10.1,>=1.7.0 in /usr/local/lib/python3.8/dist-packages (from kobert==0.2.3) (1.10.1)\n",
      "Requirement already satisfied: transformers<=4.8.1,>=4.8.1 in /usr/local/lib/python3.8/dist-packages (from kobert==0.2.3) (4.8.1)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.8/dist-packages (from onnxruntime<=1.8.0,==1.8.0->kobert==0.2.3) (3.19.4)\n",
      "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.8/dist-packages (from onnxruntime<=1.8.0,==1.8.0->kobert==0.2.3) (2.0)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.8/dist-packages (from onnxruntime<=1.8.0,==1.8.0->kobert==0.2.3) (1.21.0)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.8/dist-packages (from boto3<=1.15.18->kobert==0.2.3) (0.10.0)\n",
      "Requirement already satisfied: botocore<1.19.0,>=1.18.18 in /usr/local/lib/python3.8/dist-packages (from boto3<=1.15.18->kobert==0.2.3) (1.18.18)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from boto3<=1.15.18->kobert==0.2.3) (0.3.7)\n",
      "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.8/dist-packages (from mxnet<=1.7.0.post2,>=1.4.0->kobert==0.2.3) (0.8.4)\n",
      "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.8/dist-packages (from mxnet<=1.7.0.post2,>=1.4.0->kobert==0.2.3) (2.27.1)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch<=1.10.1,>=1.7.0->kobert==0.2.3) (4.1.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (3.6.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (6.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (21.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (2023.5.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (4.63.1)\n",
      "Requirement already satisfied: sacremoses in /usr/local/lib/python3.8/dist-packages (from transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (0.0.53)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.8/dist-packages (from transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (0.10.3)\n",
      "Requirement already satisfied: huggingface-hub==0.0.12 in /usr/local/lib/python3.8/dist-packages (from transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (0.0.12)\n",
      "Requirement already satisfied: urllib3<1.26,>=1.20 in /usr/local/lib/python3.8/dist-packages (from botocore<1.19.0,>=1.18.18->boto3<=1.15.18->kobert==0.2.3) (1.25.11)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.8/dist-packages (from botocore<1.19.0,>=1.18.18->boto3<=1.15.18->kobert==0.2.3) (2.8.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (3.0.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.20.0->mxnet<=1.7.0.post2,>=1.4.0->kobert==0.2.3) (2.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.20.0->mxnet<=1.7.0.post2,>=1.4.0->kobert==0.2.3) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.20.0->mxnet<=1.7.0.post2,>=1.4.0->kobert==0.2.3) (3.3)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (8.1.3)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (1.16.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (1.1.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: You are using pip version 22.0.4; however, version 23.1.2 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install git+https://git@github.com/SKTBrain/KoBERT.git@master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e2f029e-c5b8-4b43-b85a-0386eca3bda0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/mxnet/optimizer/optimizer.py:163: UserWarning: WARNING: New optimizer gluonnlp.optimizer.lamb.LAMB is overriding existing optimizer mxnet.optimizer.optimizer.LAMB\n",
      "  warnings.warn('WARNING: New optimizer %s.%s is overriding '\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import gluonnlp as nlp\n",
    "import numpy as np\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "import pandas as pd\n",
    "import random\n",
    "from transformers import Trainer, TrainingArguments, AutoTokenizer, AutoModelForSequenceClassification\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "\n",
    "#KoBERT\n",
    "from kobert.utils import get_tokenizer\n",
    "from kobert.pytorch_kobert import get_pytorch_kobert_model\n",
    "#transformer\n",
    "from transformers import AdamW\n",
    "from transformers.optimization import get_cosine_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb532463-6ea7-4949-96c1-52285d31ff00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "Tesla V100-SXM2-16GB\n",
      "Tesla V100-SXM2-16GB\n"
     ]
    }
   ],
   "source": [
    "#GPU 설정\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "import os\n",
    "\n",
    "n_devices = torch.cuda.device_count()\n",
    "print(n_devices)\n",
    "\n",
    "for i in range(n_devices):\n",
    "    print(torch.cuda.get_device_name(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3b82d33-f873-4420-814b-41aa5a0e031b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model. /root/kobert/dataset/.cache/kobert_v1.zip\n",
      "using cached model. /root/kobert/dataset/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"
     ]
    }
   ],
   "source": [
    "#bertmodel, vocabulary 불러오기\n",
    "bertmodel, vocab = get_pytorch_kobert_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b654e00b-18f5-4ca3-9a2d-75ebd78aef8b",
   "metadata": {},
   "source": [
    "2. Load Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6814cb60-f953-4051-a414-8261d38d0db6",
   "metadata": {},
   "source": [
    "(1) preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af2587ea-eef9-4768-8d82-3540a5b78828",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preparing_data_1(df:pd.DataFrame) -> pd.DataFrame:\n",
    "    # SettingWithCopyWarning\n",
    "    data = df.copy()\n",
    "\n",
    "    def func(c):\n",
    "        if c == \"sad\" : return \"sadness\"\n",
    "        elif c == \"anger\" : return \"angry\"\n",
    "        else : return c\n",
    "        \n",
    "    data = data[[\"발화문\", \"상황\"]]\n",
    "    data.columns = [\"sentence\", \"class\"]\n",
    "    data.reset_index(drop=True, inplace=True)\n",
    "    data[\"class\"] = data[\"class\"].apply(func)\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85fa40a2-4b17-44bb-977c-a95b8d5c01d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preparing_data_2(df:pd.DataFrame) -> pd.DataFrame:\n",
    "    # SettingWithCopyWarning\n",
    "    data = df.copy()\n",
    "    \n",
    "    def func(c):\n",
    "        if c == \"분노\" : return \"angry\"\n",
    "        elif c == \"혐오\" : return \"disgust\"\n",
    "        elif c == \"중립\" : return \"neutral\"\n",
    "        elif c == \"놀람\" : return \"surprise\"\n",
    "        elif c == \"행복\" : return \"happiness\"\n",
    "        elif c == \"공포\" : return \"fear\"\n",
    "        elif c == \"슬픔\" : return \"sadness\"\n",
    "        else : return np.nan\n",
    "\n",
    "    # cleaning data    \n",
    "    data = data[[\"Unnamed: 1\" ,\"Unnamed: 2\"]]\n",
    "    data.columns = [\"sentence\", \"class\"]\n",
    "    data.reset_index(drop=True, inplace=True)\n",
    "    data[\"class\"] = data[\"class\"].apply(func)\n",
    "    data.dropna(inplace=True)\n",
    "\n",
    "    # imbalanced data \n",
    "    \"\"\"\n",
    "    \n",
    "    # all data size\n",
    "    data.shape >= 50000\n",
    "\n",
    "    # one column data size\n",
    "    data[\"neutral\"].shape >= 40000\n",
    "    \n",
    "    # apply random undersampling\n",
    "    data[\"neutral\"].shape : 10000\n",
    "\n",
    "    \"\"\"\n",
    "    neutral_index = list(data[data[\"class\"] == \"neutral\"].index)\n",
    "    remove_index = random.sample(neutral_index,33786)\n",
    "    data.drop(remove_index, inplace=True)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "771a14f2-dd25-49df-9cad-312cf161ec84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "train1 = preparing_data_1(pd.read_csv('/root/kobert/dataset/year_4.csv', index_col=0, encoding=\"cp949\"))\n",
    "train2 = preparing_data_1(pd.read_csv('/root/kobert/dataset/year_5_1.csv', index_col=0, encoding=\"cp949\"))\n",
    "train3 = preparing_data_1(pd.read_csv('/root/kobert/dataset/year_5_2.csv', index_col=0, encoding=\"cp949\"))\n",
    "\n",
    "#\n",
    "train4 = preparing_data_2(pd.read_excel('/root/kobert/dataset/chat_korean.xlsx', index_col=0))\n",
    "\n",
    "# concat\n",
    "train = pd.DataFrame()\n",
    "train = pd.concat([train, train1], axis=0, ignore_index=True)\n",
    "train = pd.concat([train, train2], axis=0, ignore_index=True)\n",
    "train = pd.concat([train, train3], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "824270a1-0b6b-4843-8e12-6423c9c94271",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'angry': 11635,\n",
       "         'sadness': 14000,\n",
       "         'fear': 4131,\n",
       "         'disgust': 4660,\n",
       "         'neutral': 3262,\n",
       "         'happiness': 4548,\n",
       "         'surprise': 1755})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(train['class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d314d1bf-2bd3-4a45-968d-ea64c32d983d",
   "metadata": {},
   "source": [
    "(2) label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a99ef14c-1ed3-4106-a1e0-06109390d394",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[(train['class'] == \"sadness\"), 'class'] = 0 \n",
    "train.loc[(train['class'] == \"fear\"), 'class'] = 1  \n",
    "train.loc[(train['class'] == \"disgust\"), 'class'] = 2  \n",
    "train.loc[(train['class'] == \"neutral\"), 'class'] = 3  \n",
    "train.loc[(train['class'] == \"happiness\"), 'class'] = 4  \n",
    "train.loc[(train['class'] == \"angry\"), 'class'] = 5  \n",
    "train.loc[(train['class'] == \"surprise\"), 'class'] = 6  \n",
    "\n",
    "data_list = []\n",
    "for sen, label in zip(train['sentence'], train['class'])  :\n",
    "    data = []   \n",
    "    data.append(sen)\n",
    "    data.append(str(label))\n",
    "\n",
    "    data_list.append(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58e251a-d9b6-48f2-9e56-8e9f353a7411",
   "metadata": {},
   "source": [
    "(3) split train / test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d34ed6fa-d293-4910-ab13-516f27dfd1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(data_list, test_size=0.2, shuffle=True, random_state = 1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1724ae1b-edb0-499b-9303-167292fed448",
   "metadata": {},
   "source": [
    "(4) tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8c5a4418-0d5c-41cc-a214-e9f00d263718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model. /root/kobert/dataset/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"
     ]
    }
   ],
   "source": [
    "tokenizer = get_tokenizer()\n",
    "tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671fad0a-8d98-41d0-9e5f-a28a4b5b8c82",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "47a28b3b-4849-424c-93c4-33c99a15368e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTDataset(Dataset):\n",
    "    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, max_len,\n",
    "                 pad, pair):\n",
    "        transform = nlp.data.BERTSentenceTransform(\n",
    "            bert_tokenizer, max_seq_length=max_len, pad=pad, pair=pair)\n",
    "\n",
    "        self.sentences = [transform([i[sent_idx]]) for i in dataset]\n",
    "        self.labels = [np.int32(i[label_idx]) for i in dataset]\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return (self.sentences[i] + (self.labels[i], ))\n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2e7274-824e-4add-9dce-cdeb9df747be",
   "metadata": {},
   "source": [
    "(5) Setting parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a5d59336-519c-4c67-a61d-b34df74125a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 64\n",
    "batch_size = 64\n",
    "warmup_ratio = 0.1\n",
    "num_epochs = 7\n",
    "max_grad_norm = 1\n",
    "log_interval = 200\n",
    "learning_rate =  5e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f9768f5e-9118-4a71-9c23-a8443c4b99e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = BERTDataset(train, 0, 1, tok, max_len, True, False)\n",
    "data_test = BERTDataset(test, 0, 1, tok, max_len, True, False)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(data_train, batch_size=batch_size, num_workers=5)\n",
    "test_dataloader = torch.utils.data.DataLoader(data_test, batch_size=batch_size, num_workers=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "818d3daf-a71c-4816-bda3-e4ba6b1b9a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "                 bert,\n",
    "                 hidden_size = 768,\n",
    "                 num_classes=7,\n",
    "                 dr_rate=None,\n",
    "                 params=None):\n",
    "        super(BERTClassifier, self).__init__()\n",
    "        self.bert = bert\n",
    "        self.dr_rate = dr_rate\n",
    "                 \n",
    "        self.classifier = nn.Linear(hidden_size , num_classes)\n",
    "        if dr_rate:\n",
    "            self.dropout = nn.Dropout(p=dr_rate)\n",
    "    \n",
    "    def gen_attention_mask(self, token_ids, valid_length):\n",
    "        attention_mask = torch.zeros_like(token_ids)\n",
    "        for i, v in enumerate(valid_length):\n",
    "            attention_mask[i][:v] = 1\n",
    "        return attention_mask.float()\n",
    "\n",
    "    def forward(self, token_ids, valid_length, segment_ids):\n",
    "        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n",
    "        \n",
    "        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device))\n",
    "        if self.dr_rate:\n",
    "            out = self.dropout(pooler)\n",
    "        return self.classifier(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6ce2fa-9bd1-4808-b59c-bf415a4caf35",
   "metadata": {},
   "source": [
    "3. Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8579b9ed-82dc-474b-b9c8-dc04f945fe41",
   "metadata": {},
   "source": [
    "(1) load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a181d917-bb0e-44ff-989b-87c543821568",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7f83f45f9b50>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#BERT 모델 불러오기\n",
    "model = BERTClassifier(bertmodel,  dr_rate=0.5).to(device)\n",
    " \n",
    "#optimizer와 schedule 설정\n",
    "no_decay = ['bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "]\n",
    "\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate)\n",
    "loss_fn = nn.CrossEntropyLoss() # 다중분류를 위한 대표적인 loss func\n",
    "\n",
    "t_total = len(train_dataloader) * num_epochs\n",
    "warmup_step = int(t_total * warmup_ratio)\n",
    "\n",
    "scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=warmup_step, num_training_steps=t_total)\n",
    "\n",
    "#정확도 측정을 위한 함수 정의\n",
    "def calc_accuracy(X,Y):\n",
    "    max_vals, max_indices = torch.max(X, 1)\n",
    "    train_acc = (max_indices == Y).sum().data.cpu().numpy()/max_indices.size()[0]\n",
    "    return train_acc\n",
    "    \n",
    "train_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc86c05-e866-4884-b8cb-d86e2836c8fd",
   "metadata": {},
   "source": [
    "(2) training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a039fa48-e2cf-4364-9ef6-3b633f02ce4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "994469b58cd145c3a01a72e14d8f447e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/550 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 batch id 1 loss 1.9907768964767456 train acc 0.1875\n",
      "epoch 1 batch id 201 loss 0.7478275299072266 train acc 0.4095926616915423\n",
      "epoch 1 batch id 401 loss 0.48260119557380676 train acc 0.6115180798004988\n",
      "epoch 1 train acc 0.6803733766233767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_20513/3866162363.py:24: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(test_dataloader)):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "119e5afdb10444219d276fc79d2fac8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/138 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 test acc 0.8833420991117344\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fde2a2e4fad7442c8cb85dd24bfa848d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/550 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 batch id 1 loss 0.2890363931655884 train acc 0.921875\n",
      "epoch 2 batch id 201 loss 0.1554868370294571 train acc 0.8877487562189055\n",
      "epoch 2 batch id 401 loss 0.22342266142368317 train acc 0.8984180174563591\n",
      "epoch 2 train acc 0.9040990259740259\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2296bfb263bb487890206e17c02ae376",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/138 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 test acc 0.9126672802711547\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bde1443f160e425f9211b473620e646b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/550 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 batch id 1 loss 0.15736445784568787 train acc 0.984375\n",
      "epoch 3 batch id 201 loss 0.032751016318798065 train acc 0.9290267412935324\n",
      "epoch 3 batch id 401 loss 0.19341477751731873 train acc 0.9342269326683291\n",
      "epoch 3 train acc 0.9377191558441558\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "774ab91f41d64a3abb19f807d3592563",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/138 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 test acc 0.9193475338943432\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "add492da48254f5fbd967075a794569a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/550 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 batch id 1 loss 0.10736618936061859 train acc 0.953125\n",
      "epoch 4 batch id 201 loss 0.07959021627902985 train acc 0.9506374378109452\n",
      "epoch 4 batch id 401 loss 0.14458265900611877 train acc 0.9514884663341646\n",
      "epoch 4 train acc 0.953713474025974\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb7982edfd8e4721ab32c8612cdda7f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/138 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 test acc 0.925574888966807\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33f02786d4364dccbb6b6963812c09ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/550 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 batch id 1 loss 0.02203626185655594 train acc 1.0\n",
      "epoch 5 batch id 201 loss 0.0033633182756602764 train acc 0.966806592039801\n",
      "epoch 5 batch id 401 loss 0.11451438814401627 train acc 0.96875\n",
      "epoch 5 train acc 0.9700730519480519\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7a1757b315146f48076448a6cd31ddd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/138 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 test acc 0.9256881136044881\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaffa9ec97924ab488ce9221611bb5dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/550 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6 batch id 1 loss 0.002368479035794735 train acc 1.0\n",
      "epoch 6 batch id 201 loss 0.001440887339413166 train acc 0.9761349502487562\n",
      "epoch 6 batch id 401 loss 0.05691201984882355 train acc 0.9776730049875312\n",
      "epoch 6 train acc 0.978676948051948\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4bbb61b95864a3f8fc9be4abe8cc39c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/138 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6 test acc 0.9279526063581113\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9060811c80c4f04ab86b75174ed407a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/550 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7 batch id 1 loss 0.001987518509849906 train acc 1.0\n",
      "epoch 7 batch id 201 loss 0.004437095019966364 train acc 0.982431592039801\n",
      "epoch 7 batch id 401 loss 0.051512446254491806 train acc 0.9834008728179551\n",
      "epoch 7 train acc 0.9839366883116882\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e344ff410c34b529b00bc76986deaa1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/138 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7 test acc 0.929658280738663\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "for e in range(num_epochs):\n",
    "    train_acc = 0.0\n",
    "    test_acc = 0.0\n",
    "    model.train()\n",
    "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm(train_dataloader)):\n",
    "        optimizer.zero_grad()\n",
    "        token_ids = token_ids.long().to(device)\n",
    "        segment_ids = segment_ids.long().to(device)\n",
    "        valid_length= valid_length\n",
    "        label = label.long().to(device)\n",
    "        out = model(token_ids, valid_length, segment_ids)\n",
    "        loss = loss_fn(out, label)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "        optimizer.step()\n",
    "        scheduler.step()  # Update learning rate schedule\n",
    "        train_acc += calc_accuracy(out, label)\n",
    "        if batch_id % log_interval == 0:\n",
    "            print(\"epoch {} batch id {} loss {} train acc {}\".format(e+1, batch_id+1, loss.data.cpu().numpy(), train_acc / (batch_id+1)))\n",
    "    print(\"epoch {} train acc {}\".format(e+1, train_acc / (batch_id+1)))\n",
    "    \n",
    "    model.eval()\n",
    "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(test_dataloader)):\n",
    "        token_ids = token_ids.long().to(device)\n",
    "        segment_ids = segment_ids.long().to(device)\n",
    "        valid_length= valid_length\n",
    "        label = label.long().to(device)\n",
    "        out = model(token_ids, valid_length, segment_ids)\n",
    "        test_acc += calc_accuracy(out, label)\n",
    "    print(\"epoch {} test acc {}\".format(e+1, test_acc / (batch_id+1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e192418b-8387-4702-9350-6ef940911680",
   "metadata": {},
   "source": [
    "(3) save the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3ea40c73-c938-4141-8554-7de20252d0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '/root/kobert/' \n",
    "torch.save(model, PATH + 'KoBERT_ver1.pt')  # 전체 모델 저장\n",
    "torch.save(model.state_dict(), PATH + 'KoBERT_ver1_state_dict.pt')  # 모델 객체의 state_dict 저장\n",
    "torch.save({\n",
    "    'model': model.state_dict(),\n",
    "    'optimizer': optimizer.state_dict()\n",
    "}, PATH + 'all.tar')  # 여러 가지 값 저장, 학습 중 진행 상황 저장을 위해 epoch, loss 값 등 일반 scalar값 저장 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d78cbd-6515-4382-b40c-0acfc0f6ff0e",
   "metadata": {},
   "source": [
    "(4) save the requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f7fe9e47-c6b3-4013-a4ad-687dbbeef85f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1381db6-fa60-4e7f-b57c-67a71f788b9a",
   "metadata": {},
   "source": [
    "3. Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a6b3b415-21db-44c4-a70e-53bb6c09b689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model. /root/kobert/dataset/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"
     ]
    }
   ],
   "source": [
    "tokenizer = get_tokenizer()\n",
    "tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)\n",
    "\n",
    "def predict(predict_sentence):\n",
    "\n",
    "    data = [predict_sentence, '0']\n",
    "    dataset_another = [data]\n",
    "\n",
    "    another_test = BERTDataset(dataset_another, 0, 1, tok, max_len, True, False)\n",
    "    test_dataloader = torch.utils.data.DataLoader(another_test, batch_size=batch_size, num_workers=5)\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(test_dataloader)):\n",
    "        token_ids = token_ids.long().to(device)\n",
    "        segment_ids = segment_ids.long().to(device)\n",
    "\n",
    "        valid_length= valid_length\n",
    "        label = label.long().to(device)\n",
    "\n",
    "        out = model(token_ids, valid_length, segment_ids)\n",
    "\n",
    "\n",
    "        test_eval=[]\n",
    "        for i in out:\n",
    "            logits=i\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "\n",
    "            if np.argmax(logits) == 0:\n",
    "                test_eval.append(\"슬픔이\")\n",
    "            elif np.argmax(logits) == 1:\n",
    "                test_eval.append(\"공포가\")\n",
    "            elif np.argmax(logits) == 2:\n",
    "                test_eval.append(\"혐오가\")\n",
    "            elif np.argmax(logits) == 3:\n",
    "                test_eval.append(\"중립이\")\n",
    "            elif np.argmax(logits) == 4:\n",
    "                test_eval.append(\"행복이\")\n",
    "            elif np.argmax(logits) == 5:\n",
    "                test_eval.append(\"화남이\")\n",
    "            elif np.argmax(logits) == 6:\n",
    "                test_eval.append(\"놀람이\")\n",
    "\n",
    "            #test_eval.append(np.argmax(logits))\n",
    "\n",
    "        print(\">> 입력하신 내용에서 \" + test_eval[0] + \" 느껴집니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2de65167-4e12-4dbf-acee-4c62c24c122e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "하고싶은 말을 입력해주세요 :  안녕?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_20513/4120038116.py:14: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(test_dataloader)):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db0caeb18bf241fc898de8c1508901f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> 입력하신 내용에서 중립이 느껴집니다.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "하고싶은 말을 입력해주세요 :  너 덕분에 할 수 있었어 고마워ㅠㅠ\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1fb56c8ae334fa0b7a4a0dff5158974",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> 입력하신 내용에서 행복이 느껴집니다.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "하고싶은 말을 입력해주세요 :  엥 진짜로 ?? 심각한데..;\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50a4416bd3914890acdc40f81fce5fec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> 입력하신 내용에서 중립이 느껴집니다.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "하고싶은 말을 입력해주세요 :  왜 자꾸 하지 말란 짓을 골라서 하냐.. 뭐하자는거임?\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77de544da8da4a76a51a287f39fedb1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> 입력하신 내용에서 화남이 느껴집니다.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "하고싶은 말을 입력해주세요 :  엥 진짜로 ?? 심각한데,,\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1006cd638ee40b7ae27824637caad2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> 입력하신 내용에서 중립이 느껴집니다.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "하고싶은 말을 입력해주세요 :  3시까지 만나자\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a2acd01a2f7499fab58ab6015562c50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> 입력하신 내용에서 슬픔이 느껴집니다.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "하고싶은 말을 입력해주세요 :   갑자기 무섭게 왜그래..\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f0b0811a06b4453a4af7f70edacb27b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> 입력하신 내용에서 공포가 느껴집니다.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "하고싶은 말을 입력해주세요 :  만나서 얘기해 힘들다.. 이제\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b7e80433a254767bb1b727e1b4895e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> 입력하신 내용에서 화남이 느껴집니다.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "하고싶은 말을 입력해주세요 :  이번에는 회의 참석 못할것 같아 미안,,\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7107e492bb84e08990d866ffd955974",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> 입력하신 내용에서 슬픔이 느껴집니다.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "하고싶은 말을 입력해주세요 :  오키~ 내일봐\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e8b789e11364eb1a1e2dcf2ed070f07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> 입력하신 내용에서 중립이 느껴집니다.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "하고싶은 말을 입력해주세요 :  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f10a46bfd2f47cd8d08c2a376a278d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> 입력하신 내용에서 혐오가 느껴집니다.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "하고싶은 말을 입력해주세요 :  0\n"
     ]
    }
   ],
   "source": [
    "#질문 무한반복하기! 0 입력시 종료\n",
    "end = 1\n",
    "while end == 1 :\n",
    "    sentence = input(\"하고싶은 말을 입력해주세요 : \")\n",
    "    if sentence == \"0\" :\n",
    "        break\n",
    "    predict(sentence)\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
