{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9babc168-662e-441d-9902-972bb1d66c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.10.1+cu102\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "311cd598-58c6-4b6d-bb5b-54f535906aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)\n",
      "Python 3.8.10\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0c4c767-76de-4b00-addc-44088db8a213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)\n",
      "Requirement already satisfied: gluonnlp==0.8.0 in /usr/local/lib/python3.8/dist-packages (0.8.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (1.4.1)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (4.63.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from gluonnlp==0.8.0) (1.21.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.8/dist-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: You are using pip version 22.0.4; however, version 23.1.2 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gluonnlp==0.8.0 pandas tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0de92259-107f-4f91-a67e-d2389b0ab99e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)\n",
      "Requirement already satisfied: mxnet in /usr/local/lib/python3.8/dist-packages (1.7.0.post2)\n",
      "Requirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.8/dist-packages (from mxnet) (1.21.0)\n",
      "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.8/dist-packages (from mxnet) (2.27.1)\n",
      "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.8/dist-packages (from mxnet) (0.8.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.20.0->mxnet) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.20.0->mxnet) (1.25.11)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.20.0->mxnet) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.20.0->mxnet) (3.3)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: You are using pip version 22.0.4; however, version 23.1.2 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install mxnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5229e5d3-a584-4797-b3cd-d5a6396fd23d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.8/dist-packages (0.1.96)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: You are using pip version 22.0.4; however, version 23.1.2 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3299d588-7156-45df-a7a9-1dc767e67a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)\n",
      "Requirement already satisfied: openpyxl in /usr/local/lib/python3.8/dist-packages (3.1.2)\n",
      "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.8/dist-packages (from openpyxl) (1.1.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: You are using pip version 22.0.4; however, version 23.1.2 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56ad7bc6-fa45-46cc-8b3a-1f8ccc65477f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)\n",
      "Requirement already satisfied: numpy==1.21.0 in /usr/local/lib/python3.8/dist-packages (1.21.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: You are using pip version 22.0.4; however, version 23.1.2 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy==1.21.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e332e8a-1c04-4d61-ba9b-a1d75ca685a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)\n",
      "Collecting git+https://****@github.com/SKTBrain/KoBERT.git@master\n",
      "  Cloning https://****@github.com/SKTBrain/KoBERT.git (to revision master) to /tmp/pip-req-build-onun_wpp\n",
      "  Running command git clone --filter=blob:none --quiet 'https://****@github.com/SKTBrain/KoBERT.git' /tmp/pip-req-build-onun_wpp\n",
      "  Resolved https://****@github.com/SKTBrain/KoBERT.git to commit 47a69af87928fc24e20f571fe10c3cc9dd9af9a3\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: boto3<=1.15.18 in /usr/local/lib/python3.8/dist-packages (from kobert==0.2.3) (1.15.18)\n",
      "Requirement already satisfied: gluonnlp<=0.10.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from kobert==0.2.3) (0.8.0)\n",
      "Requirement already satisfied: mxnet<=1.7.0.post2,>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from kobert==0.2.3) (1.7.0.post2)\n",
      "Requirement already satisfied: onnxruntime<=1.8.0,==1.8.0 in /usr/local/lib/python3.8/dist-packages (from kobert==0.2.3) (1.8.0)\n",
      "Requirement already satisfied: sentencepiece<=0.1.96,>=0.1.6 in /usr/local/lib/python3.8/dist-packages (from kobert==0.2.3) (0.1.96)\n",
      "Requirement already satisfied: torch<=1.10.1,>=1.7.0 in /usr/local/lib/python3.8/dist-packages (from kobert==0.2.3) (1.10.1)\n",
      "Requirement already satisfied: transformers<=4.8.1,>=4.8.1 in /usr/local/lib/python3.8/dist-packages (from kobert==0.2.3) (4.8.1)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.8/dist-packages (from onnxruntime<=1.8.0,==1.8.0->kobert==0.2.3) (3.19.4)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.8/dist-packages (from onnxruntime<=1.8.0,==1.8.0->kobert==0.2.3) (1.21.0)\n",
      "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.8/dist-packages (from onnxruntime<=1.8.0,==1.8.0->kobert==0.2.3) (2.0)\n",
      "Requirement already satisfied: botocore<1.19.0,>=1.18.18 in /usr/local/lib/python3.8/dist-packages (from boto3<=1.15.18->kobert==0.2.3) (1.18.18)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.8/dist-packages (from boto3<=1.15.18->kobert==0.2.3) (0.10.0)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from boto3<=1.15.18->kobert==0.2.3) (0.3.7)\n",
      "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.8/dist-packages (from mxnet<=1.7.0.post2,>=1.4.0->kobert==0.2.3) (2.27.1)\n",
      "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.8/dist-packages (from mxnet<=1.7.0.post2,>=1.4.0->kobert==0.2.3) (0.8.4)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch<=1.10.1,>=1.7.0->kobert==0.2.3) (4.1.1)\n",
      "Requirement already satisfied: huggingface-hub==0.0.12 in /usr/local/lib/python3.8/dist-packages (from transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (0.0.12)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (3.6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (2023.5.5)\n",
      "Requirement already satisfied: sacremoses in /usr/local/lib/python3.8/dist-packages (from transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (0.0.53)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.8/dist-packages (from transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (0.10.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (4.63.1)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (6.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (21.3)\n",
      "Requirement already satisfied: urllib3<1.26,>=1.20 in /usr/local/lib/python3.8/dist-packages (from botocore<1.19.0,>=1.18.18->boto3<=1.15.18->kobert==0.2.3) (1.25.11)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.8/dist-packages (from botocore<1.19.0,>=1.18.18->boto3<=1.15.18->kobert==0.2.3) (2.8.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (3.0.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.20.0->mxnet<=1.7.0.post2,>=1.4.0->kobert==0.2.3) (2.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.20.0->mxnet<=1.7.0.post2,>=1.4.0->kobert==0.2.3) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.20.0->mxnet<=1.7.0.post2,>=1.4.0->kobert==0.2.3) (3.3)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (8.1.3)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (1.16.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (1.1.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: You are using pip version 22.0.4; however, version 23.1.2 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install git+https://git@github.com/SKTBrain/KoBERT.git@master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72abfd1e-d2fc-4145-a076-4f739b270a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/mxnet/optimizer/optimizer.py:163: UserWarning: WARNING: New optimizer gluonnlp.optimizer.lamb.LAMB is overriding existing optimizer mxnet.optimizer.optimizer.LAMB\n",
      "  warnings.warn('WARNING: New optimizer %s.%s is overriding '\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import gluonnlp as nlp\n",
    "import numpy as np\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "import pandas as pd\n",
    "import random\n",
    "from transformers import Trainer, TrainingArguments, AutoTokenizer, AutoModelForSequenceClassification\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "\n",
    "#KoBERT\n",
    "from kobert.utils import get_tokenizer\n",
    "from kobert.pytorch_kobert import get_pytorch_kobert_model\n",
    "#transformer\n",
    "from transformers import AdamW\n",
    "from transformers.optimization import get_cosine_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "208f6054-1bd0-4f48-8380-4e20015a663c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Tesla V100-FHHL-16GB\n"
     ]
    }
   ],
   "source": [
    "#GPU 설정\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "import os\n",
    "\n",
    "n_devices = torch.cuda.device_count()\n",
    "print(n_devices)\n",
    "\n",
    "for i in range(n_devices):\n",
    "    print(torch.cuda.get_device_name(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08dac7d9-f701-4686-800b-2e9cd04c3d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model. /root/.cache/kobert_v1.zip\n",
      "using cached model. /root/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"
     ]
    }
   ],
   "source": [
    "#bertmodel의 vocabulary\n",
    "bertmodel, vocab = get_pytorch_kobert_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5e2cd81-d02c-49e3-b6c3-97251cf0a71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preparing_data_1(df:pd.DataFrame) -> pd.DataFrame:\n",
    "    # SettingWithCopyWarning\n",
    "    data = df.copy()\n",
    "\n",
    "    def func(c):\n",
    "        if c == \"sad\" : return \"sadness\"\n",
    "        elif c == \"anger\" : return \"angry\"\n",
    "        else : return c\n",
    "        \n",
    "    data = data[[\"발화문\", \"상황\"]]\n",
    "    data.columns = [\"sentence\", \"class\"]\n",
    "    data.reset_index(drop=True, inplace=True)\n",
    "    data[\"class\"] = data[\"class\"].apply(func)\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f7d9fe2-40df-485d-9625-fa0697b1f6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preparing_data_2(df:pd.DataFrame) -> pd.DataFrame:\n",
    "    # SettingWithCopyWarning\n",
    "    data = df.copy()\n",
    "    \n",
    "    def func(c):\n",
    "        if c == \"분노\" : return \"angry\"\n",
    "        elif c == \"혐오\" : return \"disgust\"\n",
    "        elif c == \"중립\" : return \"neutral\"\n",
    "        elif c == \"놀람\" : return \"surprise\"\n",
    "        elif c == \"행복\" : return \"happiness\"\n",
    "        elif c == \"공포\" : return \"fear\"\n",
    "        elif c == \"슬픔\" : return \"sadness\"\n",
    "        else : return np.nan\n",
    "\n",
    "    # cleaning data    \n",
    "    data = data[[\"Unnamed: 1\" ,\"Unnamed: 2\"]]\n",
    "    data.columns = [\"sentence\", \"class\"]\n",
    "    data.reset_index(drop=True, inplace=True)\n",
    "    data[\"class\"] = data[\"class\"].apply(func)\n",
    "    data.dropna(inplace=True)\n",
    "\n",
    "    # imbalanced data \n",
    "    \"\"\"\n",
    "    \n",
    "    # all data size\n",
    "    data.shape >= 50000\n",
    "\n",
    "    # one column data size\n",
    "    data[\"neutral\"].shape >= 40000\n",
    "    \n",
    "    # apply random undersampling\n",
    "    data[\"neutral\"].shape : 10000\n",
    "\n",
    "    \"\"\"\n",
    "    neutral_index = list(data[data[\"class\"] == \"neutral\"].index)\n",
    "    remove_index = random.sample(neutral_index,33786)\n",
    "    data.drop(remove_index, inplace=True)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "afe2e545-94bf-4f18-91e2-e3fabb13e7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "train1 = preparing_data_1(pd.read_csv('/root/kobert/dataset/year_4.csv', index_col=0, encoding=\"cp949\"))\n",
    "train2 = preparing_data_1(pd.read_csv('/root/kobert/dataset/year_5_1.csv', index_col=0, encoding=\"cp949\"))\n",
    "train3 = preparing_data_1(pd.read_csv('/root/kobert/dataset/year_5_2.csv', index_col=0, encoding=\"cp949\"))\n",
    "\n",
    "\n",
    "train4 = preparing_data_2(pd.read_excel('/root/kobert/dataset/chat_korean.xlsx', index_col=0))\n",
    "\n",
    "# concat\n",
    "train = pd.DataFrame()\n",
    "train = pd.concat([train, train1], axis=0, ignore_index=True)\n",
    "train = pd.concat([train, train2], axis=0, ignore_index=True)\n",
    "train = pd.concat([train, train3], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f4993b44-f1de-4bb2-bddd-9ef5340ddd51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'angry': 11635,\n",
       "         'sadness': 14000,\n",
       "         'fear': 4131,\n",
       "         'disgust': 4660,\n",
       "         'neutral': 3262,\n",
       "         'happiness': 4548,\n",
       "         'surprise': 1755})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(train['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "903e7e28-af59-48c7-89c8-f56772e875bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#labeling\n",
    "train.loc[(train['class'] == \"sadness\"), 'class'] = 0 \n",
    "train.loc[(train['class'] == \"fear\"), 'class'] = 1  \n",
    "train.loc[(train['class'] == \"disgust\"), 'class'] = 2  \n",
    "train.loc[(train['class'] == \"neutral\"), 'class'] = 3  \n",
    "train.loc[(train['class'] == \"happiness\"), 'class'] = 4  \n",
    "train.loc[(train['class'] == \"angry\"), 'class'] = 5  \n",
    "train.loc[(train['class'] == \"surprise\"), 'class'] = 6  \n",
    "\n",
    "data_list = []\n",
    "for sen, label in zip(train['sentence'], train['class'])  :\n",
    "    data = []   \n",
    "    data.append(sen)\n",
    "    data.append(str(label))\n",
    "\n",
    "    data_list.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a342c9ea-3ec8-47eb-b32d-86bc0c05ff68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset_split\n",
    "train, test = train_test_split(data_list, test_size=0.2, shuffle=True, random_state = 1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3a8b7415-543a-4d37-8229-a4d8475af8b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model. /root/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"
     ]
    }
   ],
   "source": [
    "#tokenize\n",
    "tokenizer = get_tokenizer()\n",
    "tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d02a3b02-a362-400d-9080-f48331624c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTDataset(Dataset):\n",
    "    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, max_len,\n",
    "                 pad, pair):\n",
    "        transform = nlp.data.BERTSentenceTransform(\n",
    "            bert_tokenizer, max_seq_length=max_len, pad=pad, pair=pair)\n",
    "\n",
    "        self.sentences = [transform([i[sent_idx]]) for i in dataset]\n",
    "        self.labels = [np.int32(i[label_idx]) for i in dataset]\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return (self.sentences[i] + (self.labels[i], ))\n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4ac93a48-8941-4c8d-b933-6107d5049688",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting parameters\n",
    "max_len = 64\n",
    "batch_size = 64\n",
    "warmup_ratio = 0.1\n",
    "num_epochs = 5\n",
    "max_grad_norm = 1\n",
    "log_interval = 200\n",
    "learning_rate =  5e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "23c400c3-35ca-4707-90c0-3260a733e9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = BERTDataset(train, 0, 1, tok, max_len, True, False)\n",
    "data_test = BERTDataset(test, 0, 1, tok, max_len, True, False)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(data_train, batch_size=batch_size, num_workers=5)\n",
    "test_dataloader = torch.utils.data.DataLoader(data_test, batch_size=batch_size, num_workers=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dbe242f8-9be6-4a03-887e-250a5a5191bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "                 bert,\n",
    "                 hidden_size = 768,\n",
    "                 num_classes=7,\n",
    "                 dr_rate=None,\n",
    "                 params=None):\n",
    "        super(BERTClassifier, self).__init__()\n",
    "        self.bert = bert\n",
    "        self.dr_rate = dr_rate\n",
    "                 \n",
    "        self.classifier = nn.Linear(hidden_size , num_classes)\n",
    "        if dr_rate:\n",
    "            self.dropout = nn.Dropout(p=dr_rate)\n",
    "    \n",
    "    def gen_attention_mask(self, token_ids, valid_length):\n",
    "        attention_mask = torch.zeros_like(token_ids)\n",
    "        for i, v in enumerate(valid_length):\n",
    "            attention_mask[i][:v] = 1\n",
    "        return attention_mask.float()\n",
    "\n",
    "    def forward(self, token_ids, valid_length, segment_ids):\n",
    "        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n",
    "        \n",
    "        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device))\n",
    "        if self.dr_rate:\n",
    "            out = self.dropout(pooler)\n",
    "        return self.classifier(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "56a3851b-10f8-41cf-9765-1b79e5cbf6fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7f79807b0760>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#BERT 모델 불러오기\n",
    "model = BERTClassifier(bertmodel,  dr_rate=0.5).to(device)\n",
    " \n",
    "#optimizer와 schedule 설정\n",
    "no_decay = ['bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "]\n",
    "\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate)\n",
    "loss_fn = nn.CrossEntropyLoss() # 다중분류를 위한 대표적인 loss func\n",
    "\n",
    "t_total = len(train_dataloader) * num_epochs\n",
    "warmup_step = int(t_total * warmup_ratio)\n",
    "\n",
    "scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=warmup_step, num_training_steps=t_total)\n",
    "\n",
    "#정확도 측정을 위한 함수 정의\n",
    "def calc_accuracy(X,Y):\n",
    "    max_vals, max_indices = torch.max(X, 1)\n",
    "    train_acc = (max_indices == Y).sum().data.cpu().numpy()/max_indices.size()[0]\n",
    "    return train_acc\n",
    "    \n",
    "train_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "68157d74-c37f-4ecb-8928-cae3ed97d3f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60f99f121c4749998f6b6c39e75ab752",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/550 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 batch id 1 loss 2.0989272594451904 train acc 0.125\n",
      "epoch 1 batch id 201 loss 0.6890604496002197 train acc 0.4584110696517413\n",
      "epoch 1 batch id 401 loss 0.47729170322418213 train acc 0.6456125311720698\n",
      "epoch 1 train acc 0.708299512987013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14814/3050985376.py:25: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(test_dataloader)):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f13a978b05e4b2f8d711dcfc032d2b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/138 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 test acc 0.8888754967274428\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49acca81500044a0b582c9bdf523e0aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/550 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 batch id 1 loss 0.26583582162857056 train acc 0.90625\n",
      "epoch 2 batch id 201 loss 0.22614964842796326 train acc 0.8966884328358209\n",
      "epoch 2 batch id 401 loss 0.2796436846256256 train acc 0.9065617206982544\n",
      "epoch 2 train acc 0.9110917207792208\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed59b47f5569457192d8e864e48f6ddd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/138 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 test acc 0.9161699392239364\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f1e0797d22147c58a711f3e2e825024",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/550 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 batch id 1 loss 0.11560743302106857 train acc 0.96875\n",
      "epoch 3 batch id 201 loss 0.0584908202290535 train acc 0.9347014925373134\n",
      "epoch 3 batch id 401 loss 0.18928782641887665 train acc 0.9403834164588528\n",
      "epoch 3 train acc 0.9439894480519481\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3be4674f427c4b93b255f68b9b68d7e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/138 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 test acc 0.9230766421224872\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74ef1a4281994bf9959c129be61c2337",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/550 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 batch id 1 loss 0.014483398757874966 train acc 1.0\n",
      "epoch 4 batch id 201 loss 0.010299939662218094 train acc 0.9598880597014925\n",
      "epoch 4 batch id 401 loss 0.08909500390291214 train acc 0.9631779925187033\n",
      "epoch 4 train acc 0.9650689935064936\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94bdde77571b4c3c80142608464fb20d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/138 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 test acc 0.927726157082749\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10c943359efd4510aa57bff518546d42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/550 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 batch id 1 loss 0.016251299530267715 train acc 0.984375\n",
      "epoch 5 batch id 201 loss 0.0031632015015929937 train acc 0.9734141791044776\n",
      "epoch 5 batch id 401 loss 0.1133957952260971 train acc 0.9749844139650873\n",
      "epoch 5 train acc 0.9760064935064935\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b314d830e5b46f6bb9e2b6742eb2d54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/138 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 test acc 0.9303303237494156\n"
     ]
    }
   ],
   "source": [
    "#준비된 모델을 바탕으로 학습시키기\n",
    "from tqdm.notebook import tqdm\n",
    "for e in range(num_epochs):\n",
    "    train_acc = 0.0\n",
    "    test_acc = 0.0\n",
    "    model.train()\n",
    "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm(train_dataloader)):\n",
    "        optimizer.zero_grad()\n",
    "        token_ids = token_ids.long().to(device)\n",
    "        segment_ids = segment_ids.long().to(device)\n",
    "        valid_length= valid_length\n",
    "        label = label.long().to(device)\n",
    "        out = model(token_ids, valid_length, segment_ids)\n",
    "        loss = loss_fn(out, label)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "        optimizer.step()\n",
    "        scheduler.step()  # Update learning rate schedule\n",
    "        train_acc += calc_accuracy(out, label)\n",
    "        if batch_id % log_interval == 0:\n",
    "            print(\"epoch {} batch id {} loss {} train acc {}\".format(e+1, batch_id+1, loss.data.cpu().numpy(), train_acc / (batch_id+1)))\n",
    "    print(\"epoch {} train acc {}\".format(e+1, train_acc / (batch_id+1)))\n",
    "    \n",
    "    model.eval()\n",
    "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(test_dataloader)):\n",
    "        token_ids = token_ids.long().to(device)\n",
    "        segment_ids = segment_ids.long().to(device)\n",
    "        valid_length= valid_length\n",
    "        label = label.long().to(device)\n",
    "        out = model(token_ids, valid_length, segment_ids)\n",
    "        test_acc += calc_accuracy(out, label)\n",
    "    print(\"epoch {} test acc {}\".format(e+1, test_acc / (batch_id+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ede25259-db75-4ffd-b89a-f87f472ba3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 4가지 평가지표 사용 \n",
    "# # 정확도(accuracy), 정밀도(precision), 재현율(recall), F1 Score\n",
    "# def compute_metrics(pred):\n",
    "#     labels = pred.label_ids\n",
    "#     preds = pred.predictions.argmax(-1)\n",
    "#     precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n",
    "#     acc = accuracy_score(labels, preds)\n",
    "#     return {\n",
    "#         'accuracy' : acc,\n",
    "#         'f1' : f1,\n",
    "#         'precision' : precision,\n",
    "#         'recall' : recall\n",
    "#     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "56ec439d-eb92-4482-8e90-640f75f96b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model. /root/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"
     ]
    }
   ],
   "source": [
    "tokenizer = get_tokenizer()\n",
    "tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)\n",
    "\n",
    "def predict(predict_sentence):\n",
    "\n",
    "    data = [predict_sentence, '0']\n",
    "    dataset_another = [data]\n",
    "\n",
    "    another_test = BERTDataset(dataset_another, 0, 1, tok, max_len, True, False)\n",
    "    test_dataloader = torch.utils.data.DataLoader(another_test, batch_size=batch_size, num_workers=5)\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(test_dataloader)):\n",
    "        token_ids = token_ids.long().to(device)\n",
    "        segment_ids = segment_ids.long().to(device)\n",
    "\n",
    "        valid_length= valid_length\n",
    "        label = label.long().to(device)\n",
    "\n",
    "        out = model(token_ids, valid_length, segment_ids)\n",
    "\n",
    "\n",
    "        test_eval=[]\n",
    "        for i in out:\n",
    "            logits=i\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "\n",
    "            if np.argmax(logits) == 0:\n",
    "                test_eval.append(\"슬픔이\")\n",
    "            elif np.argmax(logits) == 1:\n",
    "                test_eval.append(\"공포가\")\n",
    "            elif np.argmax(logits) == 2:\n",
    "                test_eval.append(\"분노가\")\n",
    "            elif np.argmax(logits) == 3:\n",
    "                test_eval.append(\"슬픔이\")\n",
    "            elif np.argmax(logits) == 4:\n",
    "                test_eval.append(\"중립이\")\n",
    "            elif np.argmax(logits) == 5:\n",
    "                test_eval.append(\"행복이\")\n",
    "            elif np.argmax(logits) == 6:\n",
    "                test_eval.append(\"혐오가\")\n",
    "\n",
    "            #test_eval.append(np.argmax(logits))\n",
    "\n",
    "        print(\">> 입력하신 내용에서 \" + test_eval[0] + \" 느껴집니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafde394-38d4-4921-9356-24a069dd2088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "하고싶은 말을 입력해주세요 :  너 도대체 나한테 왜 그래\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14814/903442604.py:14: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(test_dataloader)):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d414477425a24e5d82d7de8656749d28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> 입력하신 내용에서 행복이 느껴집니다.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "하고싶은 말을 입력해주세요 :  너 진짜 싫어\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bfe1a4588fc42caacecd5bd51cdda8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> 입력하신 내용에서 행복이 느껴집니다.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#질문 무한반복하기! 0 입력시 종료\n",
    "end = 1\n",
    "while end == 1 :\n",
    "    sentence = input(\"하고싶은 말을 입력해주세요 : \")\n",
    "    if sentence == \"0\" :\n",
    "        break\n",
    "    predict(sentence)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03976977-84a3-445d-afac-8ab7c409130d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, f'/root/kobert/trained_model/SentimentAnalysisKoBert.pt')\n",
    "torch.save(model.state_dict(), f'/root/kobert/content/drive/MyDrive/Colab Notebooks/SentimentAnalysisKOBert_StateDict.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1829b5b5-4f35-4a4f-80b6-c14b8708dcd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
