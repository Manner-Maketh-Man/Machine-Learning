{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "CHECK YOUR LABEL ENCODED\n",
    "\n",
    "label_encoding = {\"sadness\":0,\n",
    "                  \"fear\":1,\n",
    "                  \"disgust\":2,\n",
    "                  \"neutral\":3,\n",
    "                  \"happiness\":4,\n",
    "                  \"angry\":5,\n",
    "                  \"surprise\":6}\n",
    "\"\"\"\n",
    "\n",
    "label_decoding = {0:\"sadness\",\n",
    "                  1:\"fear\",\n",
    "                  2:\"disgust\",\n",
    "                  3:\"neutral\",\n",
    "                  4:\"happiness\",\n",
    "                  5:\"angry\",\n",
    "                  6:\"surprise\"}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load test text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('test_file.txt','r',encoding='UTF8')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKENIZER_NAME = \"monologg/koelectra-base-v3-discriminator\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(TOKENIZER_NAME)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('koelectra_imbalanced.pt', map_location=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_predict(sent):\n",
    "    # set my model max len \n",
    "    MAX_LEN = 64\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    tokenized_sent = tokenizer(\n",
    "        sent,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        add_special_tokens=True,\n",
    "        max_length=MAX_LEN\n",
    "    )\n",
    "\n",
    "    tokenized_sent.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(\n",
    "                input_ids = tokenized_sent[\"input_ids\"],\n",
    "                attention_mask=tokenized_sent[\"attention_mask\"],\n",
    "                token_type_ids=tokenized_sent[\"token_type_ids\"]\n",
    "        )\n",
    "\n",
    "    logits = outputs[0]\n",
    "    logits = logits.detach().cpu()\n",
    "    result = logits.argmax(-1)\n",
    "    \n",
    "    return label_decoding[np.array(result)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#######################################\n",
      "sentence   :  너 덕분에 할수 있었어 고맙다ㅠㅠㅠ\n",
      "answer     :  happiness\n",
      "prediction :  happiness\n",
      "#######################################\n",
      "sentence   :  엥 진짜로 ?? 심각한데..;\n",
      "answer     :  surprise\n",
      "prediction :  surprise\n",
      "#######################################\n",
      "sentence   :  왜 자꾸 하지 말란 짓을 골라서 하냐.. 뭐하자는거임?\n",
      "answer     :  angry\n",
      "prediction :  angry\n",
      "#######################################\n",
      "sentence   :  3시까지 만나자\n",
      "answer     :  neutral\n",
      "prediction :  neutral\n",
      "#######################################\n",
      "sentence   :  갑자기 무섭게 왜그래.. \n",
      "answer     :  fear\n",
      "prediction :  fear\n",
      "#######################################\n",
      "sentence   :  만나서 얘기해 힘들다.. 이제\n",
      "answer     :  sadness or angry\n",
      "prediction :  sadness\n",
      "#######################################\n",
      "sentence   :  이번에는 회의 참석 못할것 같아 미안,,\n",
      "answer     :  neutral and sadness\n",
      "prediction :  sadness\n",
      "#######################################\n",
      "sentence   :  오키 ~ 내일보자\n",
      "answer     :  neutral\n",
      "prediction :  neutral\n"
     ]
    }
   ],
   "source": [
    "a = 0\n",
    "for i in f.readlines():\n",
    "    answer, sentence = i.split(\":\")\n",
    "    sentence = sentence.rstrip(\"\\n\")\n",
    "\n",
    "    print(\"#######################################\")\n",
    "    print(f'sentence   : ', sentence)\n",
    "    print(f'answer     : ', answer)\n",
    "    print(f'prediction : ', sentence_predict(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
